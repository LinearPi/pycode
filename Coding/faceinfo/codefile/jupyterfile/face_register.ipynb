{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dlib\n",
    "dlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"F:\\PYcode\\coding\\faceinfo\\007.jpg\"\n",
    "img = cv2.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = dlib.image_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: F:/PYcode/coding/faceinfo/infomations/007.jpg\n",
      "Number of faces detected: 1\n",
      "Detection 0: Left: 171 Top: 206 Right: 416 Bottom: 450 Confidence: 1.0425950288772583\n"
     ]
    }
   ],
   "source": [
    "# The contents of this file are in the public domain. See LICENSE_FOR_EXAMPLE_PROGRAMS.txt\n",
    "#\n",
    "#   This example shows how to run a CNN based face detector using dlib.  The\n",
    "#   example loads a pretrained model and uses it to find faces in images.  The\n",
    "#   CNN model is much more accurate than the HOG based model shown in the\n",
    "#   face_detector.py example, but takes much more computational power to\n",
    "#   run, and is meant to be executed on a GPU to attain reasonable speed.\n",
    "#\n",
    "#   You can download the pre-trained model from:\n",
    "#       http://dlib.net/files/mmod_human_face_detector.dat.bz2\n",
    "#\n",
    "#   The examples/faces folder contains some jpg images of people.  You can run\n",
    "#   this program on them and see the detections by executing the\n",
    "#   following command:\n",
    "#       ./cnn_face_detector.py mmod_human_face_detector.dat ../examples/faces/*.jpg\n",
    "#\n",
    "#\n",
    "# COMPILING/INSTALLING THE DLIB PYTHON INTERFACE\n",
    "#   You can install dlib using the command:\n",
    "#       pip install dlib\n",
    "#\n",
    "#   Alternatively, if you want to compile dlib yourself then go into the dlib\n",
    "#   root folder and run:\n",
    "#       python setup.py install\n",
    "#\n",
    "#   Compiling dlib should work on any operating system so long as you have\n",
    "#   CMake installed.  On Ubuntu, this can be done easily by running the\n",
    "#   command:\n",
    "#       sudo apt-get install cmake\n",
    "#\n",
    "#   Also note that this example requires Numpy which can be installed\n",
    "#   via the command:\n",
    "#       pip install numpy\n",
    "import sys\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# if len(sys.argv) < 3:\n",
    "#     print(\n",
    "#         \"Call this program like this:\\n\"\n",
    "#         \"   ./cnn_face_detector.py mmod_human_face_detector.dat ../examples/faces/*.jpg\\n\"\n",
    "#         \"You can get the mmod_human_face_detector.dat file from:\\n\"\n",
    "#         \"    http://dlib.net/files/mmod_human_face_detector.dat.bz2\")\n",
    "#     exit()\n",
    "\n",
    "model_url = \"F:/PYcode/coding/faceinfo/dlib_shapedata/mmod_human_face_detector.dat\"\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(model_url)\n",
    "win = dlib.image_window()\n",
    "\n",
    "img_url = \"F:/PYcode/coding/faceinfo/infomations/007.jpg\"\n",
    "\n",
    "print(\"Processing file: {}\".format(img_url))\n",
    "img = cv2.imread(img_url, cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# The 1 in the second argument indicates that we should upsample the image\n",
    "# 1 time.  This will make everything bigger and allow us to detect more\n",
    "# faces.\n",
    "dets = cnn_face_detector(img, 1)\n",
    "'''\n",
    "This detector returns a mmod_rectangles object. This object contains a list of mmod_rectangle objects.\n",
    "These objects can be accessed by simply iterating over the mmod_rectangles object\n",
    "The mmod_rectangle object has two member variables, a dlib.rectangle object, and a confidence score.\n",
    "\n",
    "It is also possible to pass a list of images to the detector.\n",
    "    - like this: dets = cnn_face_detector([image list], upsample_num, batch_size = 128)\n",
    "\n",
    "In this case it will return a mmod_rectangless object.\n",
    "This object behaves just like a list of lists and can be iterated over.\n",
    "'''\n",
    "print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "for i, d in enumerate(dets):\n",
    "    print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {} Confidence: {}\".format(\n",
    "        i, d.rect.left(), d.rect.top(), d.rect.right(), d.rect.bottom(), d.confidence))\n",
    "\n",
    "rects = dlib.rectangles()\n",
    "rects.extend([d.rect for d in dets])\n",
    "\n",
    "win.clear_overlay()\n",
    "win.set_image(img)\n",
    "win.add_overlay(rects)\n",
    "dlib.hit_enter_to_continue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# if len(sys.argv) != 5:\n",
    "#     print(\n",
    "#         \"Call this program like this:\\n\"\n",
    "#         \"   ./face_clustering.py shape_predictor_5_face_landmarks.dat dlib_face_recognition_resnet_model_v1.dat ../examples/faces output_folder\\n\"\n",
    "#         \"You can download a trained facial shape predictor and recognition model from:\\n\"\n",
    "#         \"    http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2\\n\"\n",
    "#         \"    http://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2\")\n",
    "#     exit()\n",
    "\n",
    "predictor_path = r\"F:/PYcode/coding/faceinfo/dlib_shapedata/shape_predictor_5_face_landmarks.dat\"\n",
    "face_rec_model_path = r\"F:/PYcode/coding/faceinfo/dlib_shapedata/dlib_face_recognition_resnet_model_v1.dat\"\n",
    "faces_folder_path = r\"F:/PYcode/coding/faceinfo/infomations\"\n",
    "output_folder_path = r\"F:/PYcode/coding/faceinfo/infomations\"\n",
    "\n",
    "# Load all the models we need: a detector to find the faces, a shape predictor\n",
    "# to find face landmarks so we can precisely localize the face, and finally the\n",
    "# face recognition model.\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor(predictor_path)\n",
    "facerec = dlib.face_recognition_model_v1(face_rec_model_path)\n",
    "\n",
    "descriptors = []\n",
    "images = []\n",
    "\n",
    "# Now find all the faces and compute 128D face descriptors for each face.\n",
    "for f in glob.glob(os.path.join(faces_folder_path, \"*.jpg\")):\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "#     img = dlib.load_rgb_image(f)\n",
    "    img = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces.\n",
    "    dets = detector(img, 1)\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "\n",
    "    # Now process each face we found.\n",
    "    for k, d in enumerate(dets):\n",
    "        # Get the landmarks/parts for the face in box d.\n",
    "        shape = sp(img, d)\n",
    "\n",
    "        # Compute the 128D vector that describes the face in img identified by\n",
    "        # shape.  \n",
    "        face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "        descriptors.append(face_descriptor)\n",
    "        images.append((img, shape))\n",
    "\n",
    "# Now let's cluster the faces.  \n",
    "labels = dlib.chinese_whispers_clustering(descriptors, 0.5)\n",
    "num_classes = len(set(labels))\n",
    "print(\"Number of clusters: {}\".format(num_classes))\n",
    "\n",
    "# Find biggest class\n",
    "biggest_class = None\n",
    "biggest_class_length = 0\n",
    "for i in range(0, num_classes):\n",
    "    class_length = len([label for label in labels if label == i])\n",
    "    if class_length > biggest_class_length:\n",
    "        biggest_class_length = class_length\n",
    "        biggest_class = i\n",
    "\n",
    "print(\"Biggest cluster id number: {}\".format(biggest_class))\n",
    "print(\"Number of faces in biggest cluster: {}\".format(biggest_class_length))\n",
    "\n",
    "# Find the indices for the biggest class\n",
    "indices = []\n",
    "for i, label in enumerate(labels):\n",
    "    if label == biggest_class:\n",
    "        indices.append(i)\n",
    "\n",
    "print(\"Indices of images in the biggest cluster: {}\".format(str(indices)))\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.isdir(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# Save the extracted faces\n",
    "print(\"Saving faces in largest cluster to output folder...\")\n",
    "for i, index in enumerate(indices):\n",
    "    img, shape = images[index]\n",
    "    file_path = os.path.join(output_folder_path, \"face_\" + str(i))\n",
    "    # The size and padding arguments are optional with default size=150x150 and padding=0.25\n",
    "    dlib.save_face_chip(img, shape, file_path, size=150, padding=0.25)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import dlib\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "win = dlib.image_window()\n",
    "\n",
    "for f in sys.argv[1:]:\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    img = dlib.load_rgb_image(f)\n",
    "    # The 1 in the second argument indicates that we should upsample the image\n",
    "    # 1 time.  This will make everything bigger and allow us to detect more\n",
    "    # faces.\n",
    "    dets = detector(img, 1)\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "    for i, d in enumerate(dets):\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            i, d.left(), d.top(), d.right(), d.bottom()))\n",
    "\n",
    "    win.clear_overlay()\n",
    "    win.set_image(img)\n",
    "    win.add_overlay(dets)\n",
    "    dlib.hit_enter_to_continue()\n",
    "\n",
    "\n",
    "# Finally, if you really want to you can ask the detector to tell you the score\n",
    "# for each detection.  The score is bigger for more confident detections.\n",
    "# The third argument to run is an optional adjustment to the detection threshold,\n",
    "# where a negative value will return more detections and a positive value fewer.\n",
    "# Also, the idx tells you which of the face sub-detectors matched.  This can be\n",
    "# used to broadly identify faces in different orientations.\n",
    "if (len(sys.argv[1:]) > 0):\n",
    "    img = dlib.load_rgb_image(sys.argv[1])\n",
    "    dets, scores, idx = detector.run(img, 1, -1)\n",
    "    for i, d in enumerate(dets):\n",
    "        print(\"Detection {}, score: {}, face_type:{}\".format(\n",
    "            d, scores[i], idx[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\001.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\002.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\003.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\004.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\005.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\006.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\007.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\008.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\009.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\010.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\011.jpg\n",
      "Number of faces detected: 1\n",
      "Processing file: F:/PYcode/coding/faceinfo/infomations\\012.jpg\n",
      "Number of faces detected: 1\n",
      "12\n",
      "Number of clusters: 11\n",
      "Biggest cluster id number: 10\n",
      "Number of faces in biggest cluster: 2\n",
      "Indices of images in the biggest cluster: [10, 11]\n",
      "Saving faces in largest cluster to output folder...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# if len(sys.argv) != 5:\n",
    "#     print(\n",
    "#         \"Call this program like this:\\n\"\n",
    "#         \"   ./face_clustering.py shape_predictor_5_face_landmarks.dat dlib_face_recognition_resnet_model_v1.dat ../examples/faces output_folder\\n\"\n",
    "#         \"You can download a trained facial shape predictor and recognition model from:\\n\"\n",
    "#         \"    http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2\\n\"\n",
    "#         \"    http://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2\")\n",
    "#     exit()\n",
    "\n",
    "predictor_path = r\"F:/PYcode/coding/faceinfo/dlib_shapedata/shape_predictor_5_face_landmarks.dat\"\n",
    "face_rec_model_path = r\"F:/PYcode/coding/faceinfo/dlib_shapedata/dlib_face_recognition_resnet_model_v1.dat\"\n",
    "faces_folder_path = r\"F:/PYcode/coding/faceinfo/infomations\"\n",
    "output_folder_path = r\"F:/PYcode/coding/faceinfo/infomations/out\"\n",
    "\n",
    "# Load all the models we need: a detector to find the faces, a shape predictor\n",
    "# to find face landmarks so we can precisely localize the face, and finally the\n",
    "# face recognition model.\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor(predictor_path)\n",
    "facerec = dlib.face_recognition_model_v1(face_rec_model_path)\n",
    "\n",
    "descriptors = []\n",
    "images = []\n",
    "\n",
    "# Now find all the faces and compute 128D face descriptors for each face.\n",
    "for f in glob.glob(os.path.join(faces_folder_path, \"*.jpg\")):\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    img = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces.\n",
    "    dets = detector(img, 1)\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "\n",
    "    # Now process each face we found.\n",
    "    for k, d in enumerate(dets):\n",
    "        # Get the landmarks/parts for the face in box d.\n",
    "        shape = sp(img, d)\n",
    "\n",
    "        # Compute the 128D vector that describes the face in img identified by\n",
    "        # shape.  \n",
    "        face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "        descriptors.append(face_descriptor)\n",
    "        images.append((img, shape))\n",
    "# print(descriptors[0])\n",
    "print(len(descriptors))\n",
    "# Now let's cluster the faces.  \n",
    "labels = dlib.chinese_whispers_clustering(descriptors, 0.4)\n",
    "num_classes = len(set(labels))\n",
    "print(\"Number of clusters: {}\".format(num_classes))\n",
    "\n",
    "# Find biggest class\n",
    "biggest_class = None\n",
    "biggest_class_length = 0\n",
    "for i in range(0, num_classes):\n",
    "    class_length = len([label for label in labels if label == i])\n",
    "    if class_length > biggest_class_length:\n",
    "        biggest_class_length = class_length\n",
    "        biggest_class = i\n",
    "\n",
    "print(\"Biggest cluster id number: {}\".format(biggest_class))\n",
    "print(\"Number of faces in biggest cluster: {}\".format(biggest_class_length))\n",
    "\n",
    "# Find the indices for the biggest class\n",
    "indices = []\n",
    "for i, label in enumerate(labels):\n",
    "    if label == biggest_class:\n",
    "        indices.append(i)\n",
    "\n",
    "print(\"Indices of images in the biggest cluster: {}\".format(str(indices)))\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.isdir(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# Save the extracted faces\n",
    "print(\"Saving faces in largest cluster to output folder...\")\n",
    "for i, index in enumerate(indices):\n",
    "    img, shape = images[index]\n",
    "    file_path = os.path.join(output_folder_path, \"face_\" + str(i))\n",
    "    # The size and padding arguments are optional with default size=150x150 and padding=0.25\n",
    "    dlib.save_face_chip(img, shape, file_path, size=150, padding=0.25)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = []\n",
    "for i in descriptors:\n",
    "#     print(i[0])\n",
    "    lia = []\n",
    "    for num in range(len(descriptors[0]) - 1):\n",
    "        lia.append(i[num]/i[num+1])\n",
    "        print(lia)\n",
    "    lis.append([min(lia),max(lia)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
