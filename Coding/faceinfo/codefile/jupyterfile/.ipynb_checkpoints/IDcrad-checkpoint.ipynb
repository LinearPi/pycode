{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "import matplotlib.patches as mpatches\n",
    "# from skimage import io,draw,transform,color\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA5FJREFUeJzt1MENwCAQwLDS/Xc+tgCJ2BPklTUzHwDv+28HAHCG4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QMQGL4sE9RSocXsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "img = cv2.imread(r\"F:/PYcode/coding/faceinfo/imgfile/004.jpg\")\n",
    "image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "dets = detector(image, 2) \n",
    "#使用detector进行人脸检测 dets为返回的结果\n",
    "## 将识别的图像可视化\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "# ax.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "for i, face in enumerate(dets):\n",
    "    # 在图片中标注人脸，并显示\n",
    "    left = face.left()\n",
    "    top = face.top()\n",
    "    right = face.right()\n",
    "    bottom = face.bottom()\n",
    "    rect = mpatches.Rectangle((left,bottom), right - left, top - bottom,\n",
    "                                  fill=False, edgecolor='red', linewidth=1)\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e56118191f56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"F:/PYcode/coding/faceinfo/imgfile/004.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[0mimage2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrotateIdcard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;31m## 可视化修正后的结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-e56118191f56>\u001b[0m in \u001b[0;36mrotateIdcard\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcorner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIDcorner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m## 旋转后的图像\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mimage2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcorner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mimage2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m## 旋转后人脸位置\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "predictor = dlib.shape_predictor(r\"F:\\PYcode\\coding\\faceinfo\\dlib_shapedata\\shape_predictor_5_face_landmarks.dat\")\n",
    "detected_landmarks = predictor(image, dets[0]).parts()\n",
    "landmarks = np.array([[p.x, p.y] for p in detected_landmarks])\n",
    "## 将眼睛位置可视化\n",
    "# plt.figure()\n",
    "# ax = plt.subplot(111)\n",
    "# ax.imshow(image)\n",
    "# plt.axis(\"off\")\n",
    "# plt.plot(landmarks[0:4,0],landmarks[0:4,1],'ro')\n",
    "# for ii in np.arange(4):\n",
    "#     plt.text(landmarks[ii,0]-10,landmarks[ii,1]-15,ii)\n",
    "# plt.show()\n",
    "\n",
    "## 计算眼睛的倾斜角度,逆时针角度\n",
    "def twopointcor(point1,point2):\n",
    "    \"\"\"point1 = (x1,y1),point2 = (x2,y2)\"\"\"\n",
    "    deltxy = point2 - point1\n",
    "    corner = np.arctan(deltxy[1] / deltxy[0]) * 180 / np.pi\n",
    "    return corner\n",
    "\n",
    "## 计算多个角度求均值\n",
    "corner10 =  twopointcor(landmarks[1,:],landmarks[0,:])\n",
    "corner23 =  twopointcor(landmarks[3,:],landmarks[2,:])\n",
    "corner20 =  twopointcor(landmarks[2,:],landmarks[0,:])\n",
    "corner = np.mean([corner10,corner23,corner20])\n",
    "# print(corner10)\n",
    "# print(corner23)\n",
    "# print(corner20)\n",
    "# print(corner)\n",
    "\n",
    "## 计算图像的身份证倾斜的角度\n",
    "def IDcorner(landmarks):\n",
    "    \"\"\"landmarks:检测的人脸5个特征点\n",
    "       经过测试使用第0个和第2个特征点计算角度较合适\n",
    "    \"\"\"\n",
    "    corner20 =  twopointcor(landmarks[2,:],landmarks[0,:])\n",
    "    corner = np.mean([corner20])\n",
    "    return corner\n",
    "corner = IDcorner(landmarks)\n",
    "# print(corner)\n",
    "\n",
    "## 将照片转正\n",
    "def rotateIdcard(image):\n",
    "    \"image :需要处理的图像\"\n",
    "    ## 使用dlib.get_frontal_face_detector识别人脸\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    dets = detector(image, 2) #使用detector进行人脸检测 dets为返回的结果\n",
    "    ## 检测人脸的眼睛所在位置\n",
    "    predictor = dlib.shape_predictor(r\"F:\\PYcode\\coding\\faceinfo\\dlib_shapedata\\shape_predictor_5_face_landmarks.dat\")\n",
    "    detected_landmarks = predictor(image, dets[0]).parts()\n",
    "    landmarks = np.array([[p.x, p.y] for p in detected_landmarks])\n",
    "    corner = IDcorner(landmarks)\n",
    "    ## 旋转后的图像\n",
    "    image2 = transform.rotate(image,corner,clip=False)\n",
    "    image2 = np.uint8(image2*255)\n",
    "    ## 旋转后人脸位置\n",
    "    det = detector(image2, 2)\n",
    "    return image2,det\n",
    "\n",
    "## 转正身份证：\n",
    "img = cv2.imread(r\"F:/PYcode/coding/faceinfo/imgfile/004.jpg\")\n",
    "image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "image2,dets = rotateIdcard(image)\n",
    "\n",
    "## 可视化修正后的结果\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "# ax.imshow(image2)\n",
    "plt.axis(\"off\")\n",
    "# 在图片中标注人脸，并显示\n",
    "left = dets[0].left()\n",
    "top = dets[0].top()\n",
    "right = dets[0].right()\n",
    "bottom = dets[0].bottom()\n",
    "rect = mpatches.Rectangle((left,bottom), (right - left), (top - bottom),\n",
    "                          fill=False, edgecolor='red', linewidth=1) \n",
    "ax.add_patch(rect)\n",
    "\n",
    "## 照片的位置（不怎么精确）\n",
    "width = right - left\n",
    "high = top - bottom\n",
    "left2 = np.uint(left - 0.5*width)\n",
    "bottom2 = np.uint(bottom + 0.5*width)\n",
    "rect = mpatches.Rectangle((left2,bottom2), 1.8*width, 2.2*high,\n",
    "                          fill=False, edgecolor='blue', linewidth=1)\n",
    "ax.add_patch(rect)\n",
    "plt.show()\n",
    "\n",
    "## 身份证上人的照片\n",
    "top2 = np.uint(bottom2+2.2*high)\n",
    "right2 = np.uint(left2+1.8*width)\n",
    "image3 = image2[top2:bottom2,left2:right2,:]\n",
    "# plt.imshow(image3)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "# cv2.imshow('image3',image3)\n",
    "# cv2.waitKey()\n",
    "\n",
    "# ## 对图像进行处理，转化为灰度图像=>二值图像\n",
    "# imagegray = cv2.cvtColor(image2,cv2.COLOR_RGB2GRAY)\n",
    "# cv2.imshow('imagegray',imagegray)\n",
    "#\n",
    "# cv2.waitKey()\n",
    "# retval, imagebin = cv2.threshold(imagegray, 120, 255, cv2.THRESH_OTSU + cv2.THRESH_BINARY)\n",
    "# ## 将照片去除\n",
    "# imagebin[0:bottom2,left2:-1] = 255\n",
    "# # 高斯双边滤波\n",
    "# img_bilateralFilter = cv2.bilateralFilter(imagebin, 40, 75, 75)\n",
    "#\n",
    "# cv2.imshow('img_bilateralFilter',img_bilateralFilter)\n",
    "# cv2.waitKey()\n",
    "# # plt.imshow(img_bilateralFilter,cmap=plt.cm.gray)\n",
    "# #\n",
    "# # plt.axis(\"off\")\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "img=cv2.imread('img-0.png') #打开图片\n",
    "gray=cv2.cvtColor(image2,cv2.COLOR_BGR2GRAY) #灰度处理\n",
    "# cv2.imshow('gray', gray)\n",
    "retval, imagebin = cv2.threshold(gray, 50, 255, cv2.THRESH_OTSU + cv2.THRESH_BINARY)\n",
    "## 将照片去除\n",
    "imagebin[0:bottom2,left2:-1] = 255\n",
    "img_bilateralFilter = cv2.bilateralFilter(imagebin, 40, 100, 100) # 高斯双边滤波\n",
    "\n",
    "cv2.namedWindow(\"img_bilateralFilter\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('img_bilateralFilter', img_bilateralFilter)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_img = cv2.imread(r\"F:/PYcode/coding/faceinfo/codefile/jupyterfile/cam_img/004.jpg\", cv2.IMREAD_COLOR)\n",
    "phone_img = cv2.imread(r\"F:/PYcode/coding/faceinfo/codefile/jupyterfile/cam_img/45.jpg\", cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_license_img = cv2.pyrDown(license_img)\n",
    "redown_license_img = cv2.pyrDown(down_license_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(redown_license_img):\n",
    "     #人脸分类器\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # 获取人脸检测器\n",
    "    predictor = dlib.shape_predictor(r\"F:\\PYcode\\coding\\faceinfo\\dlib_shapedata\\shape_predictor_68_face_landmarks.dat\")\n",
    "    dets = detector(redown_license_img, 1)\n",
    "    for face in dets:\n",
    "        shape = predictor(redown_license_img, face)  \n",
    "        # 寻找人脸的68个标定点\n",
    "        # 遍历所有点，打印出其坐标，并圈出来\n",
    "        face_list = []\n",
    "        for pt in shape.parts():\n",
    "            pt_pos = (pt.x, pt.y)\n",
    "            face_list.append(pt_pos)\n",
    "            cv2.circle(redown_license_img, pt_pos, 2, (0, 255, 0), 1)\n",
    "    return face_list\n",
    "\n",
    "cv2.imshow('license_img',redown_license_img) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_list = get_points(redown_license_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_img_list = get_points(phone_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import FileVideoStream\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 眨眼检测\n",
    "def eye_aspect_ratio(point68list):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(point68list[36], point68list[39])\n",
    "    B = dist.euclidean(point68list[37], point68list[41])\n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(point68list[38], point68list[40])\n",
    "    # compute the eye aspect ratio\"\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    # return the eye aspect ratio\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while(1): \n",
    "    _, frame = cap.read()\n",
    "    \n",
    "     #人脸分类器\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # 获取人脸检测器\n",
    "    predictor = dlib.shape_predictor(r\"F:\\PYcode\\coding\\faceinfo\\dlib_shapedata\\shape_predictor_68_face_landmarks.dat\")\n",
    "    dets = detector(frame, 1)\n",
    "    for face in dets:\n",
    "        shape = predictor(frame, face)  \n",
    "        # 寻找人脸的68个标定点\n",
    "        # 遍历所有点，打印出其坐标，并圈出来\n",
    "        face_list = []\n",
    "        for pt in shape.parts():\n",
    "            pt_pos = (pt.x, pt.y)\n",
    "            face_list.append(pt_pos)\n",
    "            cv2.circle(frame, pt_pos, 2, (0, 255, 0), 1)\n",
    "            \n",
    "    ear_ratio = eye_aspect_ratio(face_list)\n",
    "    \n",
    "    cv2.putText(frame, \"Blinks: {:.2f}\".format(ear_ratio), (10, 30),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    cv2.imshow('frame',frame) \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
