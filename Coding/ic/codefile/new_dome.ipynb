{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pprint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 身份证的识别过程\n",
    "1. 读写图片\n",
    "2. 调整图片的大小(1000)\n",
    "3. 新建一个备用的图片\n",
    "3. 降噪\n",
    "4. ~~前后背景分离~~\n",
    "5. 自适应阀值\n",
    "5. 找出适合的矩形\n",
    "6. 求出上下左右的边(分别取出一个边)\n",
    "7. 根据边相交之后的点\n",
    "8. 做映射变换\n",
    "9. 写到文件夹里面\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "strat_time = time.time()\n",
    "img = '04.jpg'\n",
    "image_r = cv2.imread(img, cv2.IMREAD_UNCHANGED)\n",
    "new_img = np.ones_like((image_r),dtype=np.uint8)*255\n",
    "if image_r.shape[0] > 1000:\n",
    "    pro_num = 600/image_r.shape[0]\n",
    "    image_r = cv2.resize(image_r, (0,0), fx=pro_num, fy=pro_num)\n",
    "image = cv2.pyrMeanShiftFiltering(image_r, 35, 25)\n",
    "t1 = time.time() \n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 125, 1)\n",
    "\n",
    "ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "outimg, contours, hireachy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# mask = np.zeros(image.shape[:2],np.uint8)\n",
    "# bgdModel = np.zeros((1,65),np.float64)\n",
    "# fgdModel = np.zeros((1,65),np.float64)\n",
    "# rect = (20,20,image.shape[0]-20, image.shape[1]-20)\n",
    "# cv2.grabCut(image, mask, rect, bgdModel, fgdModel,5, cv2.GC_INIT_WITH_RECT)\n",
    "# mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "# img = image*mask2[:,:,np.newaxis]\n",
    "# t2 = time.time()\n",
    "# cv2.drawContours(image, contours, -1, (0,0,255), 1)\n",
    "\n",
    "for i, contour in enumerate(contours):\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area > 10000:\n",
    "\n",
    "        approxCurve = cv2.approxPolyDP(contour, 10, True)       \n",
    "        if approxCurve.shape[0] > 4:\n",
    "            cv2.drawContours(new_img, contours, i, (0,0,255), 1)\n",
    "            \n",
    "        gray_new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray_new_img, 100,200) \n",
    "#         lines = cv2.HoughLinesP(edges, 1.0, 3*np.pi/180, 100, 5, minLineLength=20, maxLineGap=20)\n",
    "        lines = cv2.HoughLinesP(edges, 20, 3*np.pi/180, 100 , minLineLength=20, maxLineGap=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = np.zeros(image.shape[:2],np.uint8)\n",
    "\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "rect = (20,20,image.shape[1]-20, image.shape[0]-20)\n",
    "cv2.grabCut(image, mask, rect, bgdModel, fgdModel,5, cv2.GC_INIT_WITH_RECT)\n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = image*mask2[:,:,np.newaxis]\n",
    "# t2 = time.time()\n",
    "# cv2.drawContours(image, contours, -1, (0,0,255), 1)\n",
    "cv2.imshow(\"mask\", mask)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"fgdModel\", fgdModel)\n",
    "cv2.imshow(\"mask2\", mask2)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "top_lines = []\n",
    "botton_lines = []\n",
    "left_lines = []\n",
    "right_lines = []\n",
    "lines2D = lines[:,0,:]\n",
    "for x1,y1,x2,y2 in lines2D[:]:\n",
    "    if abs(x1 - x2)> abs(y1 - y2):\n",
    "        if y1 < 250:\n",
    "            top_lines.append((x1,y1,x2,y2))\n",
    "    #                     cv2.line(image,(x1,y1),(x2,y2),(255,0,0),1)\n",
    "        else:\n",
    "            botton_lines.append((x1,y1,x2,y2))\n",
    "    #                     cv2.line(image,(x1,y1),(x2,y2),(0,255,0),1)\n",
    "    else:\n",
    "        if x1 < 250:\n",
    "            left_lines.append((x1,y1,x2,y2))\n",
    "    #                     cv2.line(image,(x1,y1),(x2,y2),(0,0,255),1)\n",
    "        else:\n",
    "            right_lines.append((x1,y1,x2,y2))\n",
    "    #                     cv2.line(image,(x1,y1),(x2,y2),(255,255,0),1)\n",
    "\n",
    "\n",
    "\n",
    "print(lines.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596 149 692 154\n",
      "113 409 113 329\n",
      "596 149 692 154\n",
      "703 216 703 171\n",
      "137 523 364 523\n",
      "113 409 113 329\n",
      "137 523 364 523\n",
      "703 216 703 171\n"
     ]
    }
   ],
   "source": [
    "def cross_point(line1,line2):#计算交点函数\n",
    "    x1=line1[0]#取四点坐标\n",
    "    y1=line1[1] \n",
    "    x2=line1[2]\n",
    "    y2=line1[3]\n",
    "    print(x1,y1,x2,y2)\n",
    "    \n",
    "    x3=line2[0]\n",
    "    y3=line2[1]\n",
    "    x4=line2[2]\n",
    "    y4=line2[3]\n",
    "    print(x3,y3,x4,y4)\n",
    "\n",
    "    \n",
    "    k1=(y2-y1)*1.0/(x2-x1)#计算k1,由于点均为整数，需要进行浮点数转化\n",
    "    b1=y1*1.0-x1*k1*1.0#整型转浮点型是关键\n",
    "    if (x4-x3)==0:#L2直线斜率不存在操作\n",
    "        k2=None\n",
    "        b2=0\n",
    "    else:\n",
    "        k2=(y4-y3)*1.0/(x4-x3)#斜率存在操作\n",
    "        b2=y3*1.0-x3*k2*1.0\n",
    "    if k2==None:\n",
    "        x=x3\n",
    "    else:\n",
    "        x=(b2-b1)*1.0/(k1-k2)\n",
    "    y=k1*x*1.0+b1*1.0\n",
    "    return [int(x), int(y)]\n",
    "\n",
    "A = cross_point(top_lines[0], left_lines[0])\n",
    "B = cross_point(top_lines[0], right_lines[0])\n",
    "C = cross_point(botton_lines[0], left_lines[0])\n",
    "D = cross_point(botton_lines[0], right_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners = np.float32([A,B,C,D])\n",
    "canvas = np.float32([[0, 0],[800, 0],[0,600],[800,600]])\n",
    "M = cv2.getPerspectiveTransform(corners, canvas)\n",
    "result = cv2.warpPerspective(image, M, (800, 600))\n",
    "# 10.\n",
    "i = time.localtime().tm_min\n",
    "cv2.imwrite(f\"result_done{i}.jpg\",result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"result\", result)\n",
    "cv2.imshow(\"new_img\", new_img)\n",
    "cv2.imshow(\"gray\", gray)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1333, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('00.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "if img.shape[1] > 3000:\n",
    "    scale = 800/img.shape[0]\n",
    "    image =cv2.resize(img, (0,0), fx=scale, fy=scale, interpolation=cv2.INTER_NEAREST)\n",
    "dst = cv2.GaussianBlur(image, (15, 15), 23)\n",
    "    # 4.自适应图片阀值\n",
    "gray = cv2.adaptiveThreshold(dst, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 125, 1)\n",
    "# 5. 二值化图片\n",
    "ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "# 6. 找出最大的矩形\n",
    "outimg, contours, hireachy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# 7. 求出上下左右边\n",
    "\n",
    "for i, contour in enumerate(contours):\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area > 10000:\n",
    "\n",
    "        approxCurve = cv2.approxPolyDP(contour, 10, True)       \n",
    "    #     if approxCurve.shape[0] > 4:\n",
    "        cv2.drawContours(image, contours, i, (0,0,255), 1)\n",
    "\n",
    "\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.imshow(\"graygray\", gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ic",
   "language": "python",
   "name": "ic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
