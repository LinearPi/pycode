{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9055e9cf6370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjieba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import jieba\n",
    "import numpy\n",
    "# import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m\u001b[43mZhuLangXinSong-BiaoZhun\u001b[m\u001b[m     get_info.py\r\n",
      "ZhuLangXinSong-BiaoZhun.zip \u001b[31mmaster.zip\u001b[m\u001b[m\r\n",
      "analysis_message.ipynb      resewq.py\r\n",
      "analysis_message_done.ipynb \u001b[34mstopwords\u001b[m\u001b[m\r\n",
      "ask_message.csv             suggest_message.csv\r\n",
      "\u001b[31mchromedriver\u001b[m\u001b[m                train.py\r\n",
      "complain_message.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取读取\n",
    "import pymongo\n",
    "client = pymongo.MongoClient(host='localhost', port=27017)\n",
    "db = client.PubOpinionMonitoring\n",
    "collection = db.ChinaArticle\n",
    "message = collection.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理，处理需要的数据\n",
    "need_data = pandas.DataFrame(message)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          _id   author  \\\n",
      "201  5c75401b1453365a02380b5e   作者：研究部   \n",
      "202  5c75401b1453365a02380b5f      作者：   \n",
      "203  5c75401c1453365a02380b60  作者： 研究部   \n",
      "204  5c75401d1453365a02380b61      作者：   \n",
      "205  5c75401e1453365a02380b62   作者：方倾燃   \n",
      "\n",
      "                                               content    source  \\\n",
      "201  Li+研究丨开门红！一月装机量4.98GWh  同比增长290.94%-Li+研究-电池中国...  来源：电池中国网   \n",
      "202  超威集团联手京东为消费者供应50万只汽车蓄电池-财经-电池中国网    日前，超威集团与国内...  来源：电池中国网   \n",
      "203  Li+研究丨316批新车公示电池配套分析：国轩高科跃居第二 威睿电动/东风海博首进前五-Li...  来源：电池中国网   \n",
      "204  电池企业或靠网约车打场漂亮仗？-独家观察-电池中国网     2019年，动力电池企业+网约...  来源：电池中国网   \n",
      "205  拿下国内外一线客户大订单 赢合科技2018年净利润增长近五成-锂电池-电池中国网    2月...  来源：电池中国网   \n",
      "\n",
      "                         time                                        title  \\\n",
      "201  发布时间：2019-02-18 14:37:33           Li+研究丨开门红！一月装机量4.98GWh 同比增长290.94%   \n",
      "202  发布时间：2019-02-25 14:45:04                      超威集团联手京东为消费者供应50万只汽车蓄电池   \n",
      "203  发布时间：2019-02-18 14:34:01  Li+研究丨316批新车公示电池配套分析：国轩高科跃居第二 威睿电动/东风海博首进前五   \n",
      "204  发布时间：2019-02-18 14:36:54                              电池企业或靠网约车打场漂亮仗？   \n",
      "205  发布时间：2019-02-25 14:46:02               拿下国内外一线客户大订单 赢合科技2018年净利润增长近五成   \n",
      "\n",
      "                                                   url  \n",
      "201  http://news.china.com.cn/txt/2019-02/18/conten...  \n",
      "202  http://news.china.com.cn/txt/2019-02/25/conten...  \n",
      "203  http://news.china.com.cn/txt/2019-02/18/conten...  \n",
      "204  http://news.china.com.cn/txt/2019-02/18/conten...  \n",
      "205  http://news.china.com.cn/txt/2019-02/25/conten...  \n",
      "                             _id author content    source  \\\n",
      "count                        206    203     206       204   \n",
      "unique                       206    134     194        43   \n",
      "top     5c753f1e1453365a02380b3a    作者：          来源：电池中国网   \n",
      "freq                           1     29      13        33   \n",
      "\n",
      "                            time            title  \\\n",
      "count                        203              203   \n",
      "unique                       186              202   \n",
      "top     发布时间：2019-02-12 00:19:29  第14届阿布扎比国际防务展开幕   \n",
      "freq                           7                2   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 206  \n",
      "unique                                                206  \n",
      "top     http://news.china.com.cn/2019-02/12/content_74...  \n",
      "freq                                                    1  \n",
      "(206, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 打印数据\n",
    "print(need_data.tail())\n",
    "# 打印数据描述\n",
    "print(need_data.describe())\n",
    "# 查看数据的维度\n",
    "print(need_data.shape)\n",
    "# 查看数据类型\n",
    "print(type(need_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>source</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c753c5b1453365a02380a95</td>\n",
       "      <td>作者：李超</td>\n",
       "      <td>警笛声拉响，坐在警车上的周林(化名)才缓过神来，他意识到“确实犯错了”。这一天是2018年6...</td>\n",
       "      <td>来源：中国青年报</td>\n",
       "      <td>发布时间：2019-02-26 09:01:41</td>\n",
       "      <td>“错误定位”让创业大学生误入歧途</td>\n",
       "      <td>http://news.china.com.cn/2019-02/26/content_74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5c753c5d1453365a02380a96</td>\n",
       "      <td>作者：鞠焕宗</td>\n",
       "      <td>2月22日晚，张世玉（前右一）与吕新（前右二）在北京南站等候回天津的火车。2018年对于“9...</td>\n",
       "      <td>来源：新华社</td>\n",
       "      <td>发布时间：2019-02-26 09:50:51</td>\n",
       "      <td>“90后”小夫妻的津京生活</td>\n",
       "      <td>http://news.china.com.cn/2019-02/26/content_74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5c753c5d1453365a02380a97</td>\n",
       "      <td>作者：杨毅</td>\n",
       "      <td>大连铁路警方24日发布消息称，近日，一名女性乘客乘火车旅行，在餐车上独自喝了半瓶多白酒后，在...</td>\n",
       "      <td>来源：中国新闻网</td>\n",
       "      <td>发布时间：2019-02-25 08:49:32</td>\n",
       "      <td>大连一女子火车上畅饮 酒后失态袭警被拘留</td>\n",
       "      <td>http://news.china.com.cn/2019-02/25/content_74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c753c5d1453365a02380a98</td>\n",
       "      <td>作者：佚名</td>\n",
       "      <td>法者，治之端也。2月25日，习近平总书记主持召开中央全面依法治国委员会第二次会议并发表重要讲...</td>\n",
       "      <td>来源：中央广播电视总台央视网</td>\n",
       "      <td>发布时间：2019-02-26 20:22:01</td>\n",
       "      <td>中央全面依法治国委员会新年首会 干货全在这里</td>\n",
       "      <td>http://news.china.com.cn/2019-02/26/content_74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5c753c5d1453365a02380a99</td>\n",
       "      <td>作者：佚名</td>\n",
       "      <td>来设想这样一种情况：你从来没有去注册过公司，可不知什么时候你名下却多了一家甚至几家、几十家公...</td>\n",
       "      <td>来源：央视新闻客户端</td>\n",
       "      <td>发布时间：2019-02-26 08:46:31</td>\n",
       "      <td>男子莫名成公司老板上老赖名单：奔波300多天难解决</td>\n",
       "      <td>http://news.china.com.cn/2019-02/26/content_74...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  author  \\\n",
       "0  5c753c5b1453365a02380a95   作者：李超   \n",
       "1  5c753c5d1453365a02380a96  作者：鞠焕宗   \n",
       "2  5c753c5d1453365a02380a97   作者：杨毅   \n",
       "3  5c753c5d1453365a02380a98   作者：佚名   \n",
       "4  5c753c5d1453365a02380a99   作者：佚名   \n",
       "\n",
       "                                             content          source  \\\n",
       "0  警笛声拉响，坐在警车上的周林(化名)才缓过神来，他意识到“确实犯错了”。这一天是2018年6...        来源：中国青年报   \n",
       "1  2月22日晚，张世玉（前右一）与吕新（前右二）在北京南站等候回天津的火车。2018年对于“9...          来源：新华社   \n",
       "2  大连铁路警方24日发布消息称，近日，一名女性乘客乘火车旅行，在餐车上独自喝了半瓶多白酒后，在...        来源：中国新闻网   \n",
       "3  法者，治之端也。2月25日，习近平总书记主持召开中央全面依法治国委员会第二次会议并发表重要讲...  来源：中央广播电视总台央视网   \n",
       "4  来设想这样一种情况：你从来没有去注册过公司，可不知什么时候你名下却多了一家甚至几家、几十家公...      来源：央视新闻客户端   \n",
       "\n",
       "                       time                      title  \\\n",
       "0  发布时间：2019-02-26 09:01:41           “错误定位”让创业大学生误入歧途   \n",
       "1  发布时间：2019-02-26 09:50:51              “90后”小夫妻的津京生活   \n",
       "2  发布时间：2019-02-25 08:49:32       大连一女子火车上畅饮 酒后失态袭警被拘留   \n",
       "3  发布时间：2019-02-26 20:22:01     中央全面依法治国委员会新年首会 干货全在这里   \n",
       "4  发布时间：2019-02-26 08:46:31  男子莫名成公司老板上老赖名单：奔波300多天难解决   \n",
       "\n",
       "                                                 url  \n",
       "0  http://news.china.com.cn/2019-02/26/content_74...  \n",
       "1  http://news.china.com.cn/2019-02/26/content_74...  \n",
       "2  http://news.china.com.cn/2019-02/25/content_74...  \n",
       "3  http://news.china.com.cn/2019-02/26/content_74...  \n",
       "4  http://news.china.com.cn/2019-02/26/content_74...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理数据\n",
    "# 清理内容字符数小于6的数据\n",
    "need_data = need_data[need_data['content'].str.len() > 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'snownlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bb70a4378724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m 在这里，我们简单地假设大于0.66表示积极，低于0.33表示消极，其他表示中立。\"\"\"\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnownlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSnowNLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# #一个demo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'snownlp'"
     ]
    }
   ],
   "source": [
    "# 情感分析\n",
    "\"\"\"\n",
    "在这部分内容中，我们调用了SnowNLP的情感分析，它是一个python写的类库，可以方便的处理中文文本内容，不用我们实现其中具体的代码。\n",
    "一般来说，情感分析的目的是为了找出作者观点的态度，是正向还是负向，或者更具体的，我们希望知道他的情绪。\n",
    "在这里，我们希望了解到好友签名所表达出来的情感是积极的，还是中立、负面的，\n",
    "比如说在以下例子中，我们对\"这个商品我非常喜欢，颜色很合我意！\"这句话进行了预处理，并通过训练好的模型预测其的情感。\n",
    "在这里，我们简单地假设大于0.66表示积极，低于0.33表示消极，其他表示中立。\"\"\"\n",
    "\n",
    "from snownlp import SnowNLP\n",
    "\n",
    "# #一个demo\n",
    "# text = \"这个商品我非常喜欢，颜色很合我意！\"\n",
    "# sentiment = SnowNLP(text).sentiments\n",
    "# print(sentiment)\n",
    "\n",
    "\n",
    "# 用一个列表存储经过情感分析处理的数据\n",
    "sentiments = []\n",
    "for i in tList:\n",
    "    sentiments.append(SnowNLP(i).sentiments) \n",
    "    \n",
    "# 打印数据\n",
    "print(sentiments)\n",
    "\n",
    "# 使用一个字典返回情感分析统计的数据\n",
    "sentiments_dict = {\"positive\": 0,\n",
    "                    \"neutral\": 0,\n",
    "                    \"negative\": 0}\n",
    "\n",
    "for i in sentiments:\n",
    "    if i > 0.66:\n",
    "        sentiments_dict[\"positive\"] += 1\n",
    "    elif 0.33 <= i <= 0.66:\n",
    "        sentiments_dict[\"neutral\"] += 1\n",
    "    elif 0.33 > i:\n",
    "        sentiments_dict[\"negative\"] += 1\n",
    "\n",
    "print(sentiments_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiments_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8cca0e7f09d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m###  打印试试看看图片，可以用于前端展示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mu'Negative'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mu'Neutral'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mu'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentiments_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"negative\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mentiments_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"neutral\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiments_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"positive\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Sentiment Analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentiments_dict' is not defined"
     ]
    }
   ],
   "source": [
    "###  打印试试看看图片，可以用于前端展示\n",
    "labels = [u'Negative',u'Neutral',u'Positive']\n",
    "values = (sentiments_dict[\"negative\"] , entiments_dict[\"neutral\"], sentiments_dict[\"positive\"])\n",
    "plt.xlabel(u'Sentiment Analysis')\n",
    "plt.ylabel(u'Number')\n",
    "plt.xticks(range(3),labels)\n",
    "plt.bar(range(3), values)\n",
    "\n",
    "plt.title('Sentiment Analysis of OPA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "# 数据转列表 列表才可以使用数据\n",
    "content = need_data.content.values.tolist()\n",
    "print(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2月19日下午，国务委员兼国防部长魏凤和在八一大楼会见了来访的越南国防部副部长阮志咏。李晓伟摄国务委员兼国防部长魏凤和19日在北京八一大楼会见了来访的越南国防部副部长阮志咏。魏凤和说，中越友谊根基深厚，理想信念相通，关系特殊重要，是具有战略意义的命运共同体。近年来，在习近平总书记和阮富仲总书记共同引领下，中越全面战略合作伙伴关系保持健康稳定发展势头。中国军队愿同越军共同努力，落实好两党两国高层重要共识，加强战略沟通协调，深化各领域交流合作，妥善处理矛盾分歧，相互理解、相互支持、相互帮助，推动两军关系跨上新台阶，为维护两国根本利益、维护地区安全稳定作出积极贡献。阮志咏表示，越共中央、中央军委珍视越中传统友谊，高度重视发展两国两军关系，愿与中方共同努力，进一步深化各领域务实交流合作，推动越中两国两军关系一年更比一年好。军委联合参谋部副参谋长邵元明、越南驻华大使邓明魁等参加会见。（尹航）2月19日下午，国务委员兼国防部长魏凤和在八一大楼会见了来访的越南国防部副部长阮志咏。李晓伟摄'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "content[random.randint(1,197)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/mk/b4xd_dcs6_dc714m79rzbw7c0000gn/T/jieba.cache\n",
      "Loading model cost 0.891 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "# 使用分词，把文章分为单独词语\n",
    "content_s = []\n",
    "for i in content:\n",
    "    current_mess = jieba.lcut(i)\n",
    "    # 判断词语\n",
    "    if len(current_mess) > 2 and current_mess!='\\r\\n' and current_mess != ' ': \n",
    "        content_s.append(current_mess)\n",
    "print(len(content_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content = pandas.DataFrame({\"contene_s\":content_s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['争夺', '激烈', '！', '340', '亿元', '国内', '市场需求', ' ', '锂电', '设备', '行业', '增速', '达', '30%', '-', '独家', '观察', '-', '电池', '中国', '网', '\\xa0', ' ', '\\xa0', ' ', '进入', '2019', '年', '以来', '，', '已经', '有', '多家', '锂电', '设备', '企业', '发布', '2018', '年度', '业绩', '预告', '和', '年报', '，', '受益', '于', '锂电池', '行业', '的', '高', '景气', '发展', '，', '赢合', '科技', '、', '先导', '智能', '等', '锂电', '设备', '龙头企业', '成绩', '喜人', '。', '1', '月', '30', '日', '，', '先导', '智能', '发布', '业绩', '预告', '，', '公司', '预计', '2018', '年度', '归属', '上市公司', '股东', '的', '净利润', '为', '6.72', '亿元', '至', '8.33', '亿元', '，', '同比', '增长', '25.00%', '至', '55.00%', '。', '先导', '智能', '表示', '，', '得益于', '锂电池', '行业', '快速', '持续', '发展', '，', '公司', '在', '稳定', '原有', '客户', '的', '基础', '上', '，', '积极', '开拓', '新', '客户', '，', '锂电池', '相关', '设备', '的', '生产', '销售', '业绩', '较', '去年同期', '有', '显著', '提升', '。', '1', '月', '22', '日', '，', '金银', '河', '发布', '2018', '年', '年报', '，', '报告', '期内', '实现', '营业', '收入', '6.42', '亿元', '，', '同比', '增长', '31.03%', '。', '同时', '，', '金银', '河', '还', '发布', '了', '2019', '年', '第一季度', '业绩', '预告', '，', '预计', '2019', '年', '一季度', '实现', '归属于', '上市公司', '股东', '的', '净利润', '为', '394.22', '万元', '-', '473.06', '万元', '，', '同比', '上升', '0', '-', '20%', '。', '1', '月', '14', '日', '，', '赢合', '科技', '发布', '2018', '年度', '业绩', '预告', '称', '，', '预计', '2018', '年度', '净利润', '为', '3.1', '亿元', '-', '3.5', '亿元', '，', '同比', '增长', '40%', '-', '58%', '。', '报告', '期内', '，', '赢合', '科技', '积极', '拓展', '市场', '，', '与', 'LG', '化学', '、', '宁德', '时代', '、', '比亚迪', '和', '孚', '能', '科技', '等', '知名', '客户', '签订', '了', '销售', '合同', '，', '2018', '年', '实现', '订单', '金额', '28.5', '亿元', '，', '客户', '结构', '持续', '提升', '。', '340', '亿元', '的', '市场需求', '近年来', '，', '锂电池', '生产', '企业', '爆炸式', '增长', '推动', '了', '我国', '锂电池', '设备', '产业', '的', '快速', '发展', '。', '而', '在', '未来', '，', '锂电池', '企业', '将', '迎来', '新一轮', '扩张', '狂潮', '。', '业内', '预计', '2019', '-', '2020', '年', '国内', '电池', '业', '新建', '产能', '复合', '增速', '将', '达', '30%', '，', '结合', '动力电池', '企业', '产能', '扩建', '规划', '，', '预计', '2019', '年', '和', '2020', '年', '国内', '动力电池', '新建', '产能', '将', '达', '80GWh', '和', '100GWh', '，', '将', '分别', '增长', '33%', '和', '25%', '。', '随着', '国内', '宁德', '时代', '、', '比亚迪', '等', '电池', '企业', '巨头', '旺盛', '的', '扩产', '需求', '，', '三星', 'SDI', '、', 'LG', '化学', '等', '海外', '电池', '企业', '在', '华', '产能', '扩张', '也', '将', '陆续', '展开', '，', '预计', '锂电', '设备', '行业', '2019', '年', '订单', '量', '将', '会', '大幅', '增长', '。', '据', '业内', '机构', '预计', '，', '未来', '5', '年', '锂电', '设备', '行业', '增速', '将', '保持', '在', '30%', '左右', '。', '2020', '年仅', '国内', '市场需求', '就', '将', '达到', '340', '亿元', '，', '国产', '设备', '产值', '有望', '突破', '270', '亿元', '。', '对于', '锂电', '设备', '厂商', '来说', '，', '这', '其中', '蕴含着', '大量', '的', '市场', '机会', '。', '市场', '集中度', '进一步', '提升', '在', '市场需求', '不断扩大', '的', '同时', '，', '锂电', '设备', '行业', '集中度', '也', '在', '逐渐', '提升', '，', '竞争', '日趋激烈', '。', '数据', '显示', '，', '2018', '年', '我国', '锂电', '设备', '企业', '前', '10', '名', '的', '市', '占率', '超过', '60%', '，', '未来', '两至', '三年', '有望', '突破', '80%', '；', '同时', '在', '锂电', '设备', '的', '各个', '细分', '领域', '也', '诞生', '了', '一批', '龙头企业', '。', '当前', '锂电', '设备', '行业', '内', '的', '主要', '竞争', '方向', '为', '核心技术', '的', '竞争', '。', '各', '企业', '自主', '研发', '的', '核心技术', '，', '主要', '是', '通用', '技术', '在', '锂电', '设备', '各类', '产品', '生产', '制造', '中', '的', '应用', '，', '以及', '与', '下游', '锂电', '生产工艺', '的', '适应', '情况', '，', '最终', '体现', '在', '产品', '的', '一致性', '、', '稳定性', '等', '性能', '上', '。', '随着', '动力电池', '向', '高能量', '密度', '和', '高品质', '发展', '，', '将', '促进', '对', '设备', '技术', '要求', '的', '提升', '，', '进入', '下游', '头部', '动力电池', '企业', '的', '设备', '供应商', '，', '将', '受益', '于', '新一轮', '动力电池', '扩建', '和', '集中度', '提升', '，', '锂电', '设备', '产业链', '各', '环节', '的', '优质', '设备', '供应商', '将', '迎来', '新一轮', '发展', '机会', '，', '有望', '超越', '行业', '增长', '。', '高精度', '、', '全', '自动化', '是', '未来', '趋势', '锂电', '设备', '国产化率', '提升', '，', '高精度', '、', '全', '自动化', '是', '未来', '的', '发展趋势', '。', '近年来', '，', '国产', '锂电', '设备', '的', '技术', '已有', '了', '较大', '进步', '。', '有', '数据', '显示', '，', '早', '在', '2017', '年', '前端', '、', '中端', '、', '后', '端', '锂电', '设备', '的', '总体', '国产化率', '就', '分别', '达到', '88%', '、', '90%', '以上', '、', '95%', '以上', '，', '已', '逐步', '打入', '日', '韩', '锂电池', '企业', '的', '生产线', '。', '目前', '，', '我国', '动力电池', '制造', '生产线', '的', '自动化', '水平', '偏低', '，', '较', '国际', '龙头企业', '85%', '以上', '的', '自动化', '率', '存在', '较大', '差距', '，', '在', '动力电池', '性能', '要求', '越来越', '高', '的', '趋势', '下', '，', '锂电', '设备', '的', '全', '自动化', '和', '高精度', '化将', '成为', '发展趋势', '。', '全', '自动化', '和', '高精度', '化', '的', '锂电池', '生产', '设备', '，', '将', '在', '保证', '锂电池', '生产工艺', '的', '基础', '上', '，', '使', '生产', '出', '的', '锂电池', '具有', '较', '好', '的', '一致性', '、', '高', '可靠', '的', '安全', '性能', '和', '直通', '良率', '，', '从而', '降低生产', '成本', '。', '如', '比亚迪', '、', '宁德', '时代', '等', '一线', '动力电池', '企业', '已经', '将', '机器人', '技术', '导入', '锂电', '生产线', '，', '通过', '工业', '机器人', '、', 'AGV', '小车', '等', '自动化', '设备', '来', '提高', '生产', '效率', '和', '电池', '一致性', '。', '为', '提升', '高精度', '化', '和', '自动化', '，', '国内', '主流', '锂电', '设备', '企业', '在', '设备', '高端化', '和', '整线', '布局', '上', '同时', '发力', '，', '企业', '通过', '收购', '和', '加大', '研发', '的', '方式', '提升', '设备', '高端化', '水平', '，', '赢合', '科技', '、', '先导', '智能', '已', '完成', '整线', '布局', '，', '科恒', '股份', '、', '璞', '泰来', '等', '也', '正', '加速', '布局', '。', '向', '国际', '市场', '大举', '进军', '随着', '国际', '锂电', '巨头', '大规模', '在', '国内', '布局', '，', '全球', '锂电池', '制造', '中心', '正向', '中国', '转移', '。', '国内', '一些', '优质', '的', '锂电', '设备', '制造商', '率先', '转向', '全', '自动化', '控制', '、', '可', '实现', '大规模', '稳定', '生产', '的', '锂电池', '装备', '研发', '与', '制造', '，', '使', '国产', '锂电池', '装备', '向', '国际', '水平', '发展', '，', '我国', '锂电池', '装备', '开始', '走向', '全球化', '。', '目前', '，', '我国', '锂电', '设备', '企业', '已', '覆盖', '了', '动力电池', '生产', '全部', '环节', '，', '先导', '智能', '、', '赢合', '科技', '等', '优质', '供应商', '的', '设备', '性能', '已经', '达到', '国际', '先进', '水平', '，', '也', '开始', '接到', '国际', '订单', '。', '2018', '年', '9', '月', '，', '赢合', '科技', '与', 'LG', '化学', '签订', '了', '《', '采购', '协议', '》', '，', 'LG', '化学', '向', '赢合', '科技', '采购', '19', '台', '卷绕', '机', '(', '含', 'J', '/', 'R', '下料机', ')', '；', '2018', '年', '12', '月', '，', '先导', '智能', '与', '特斯拉', '签订', '4300', '万元', '锂电池', '设备', '供应', '合同', '。', '预计', '未来', '将', '有', '更', '多', '国内', '锂电', '设备', '龙头企业', '进军', '海外', '市场', '，', '走向', '更加', '广阔', '的', '国际化', '蓝海', '。']\n",
      "193\n"
     ]
    }
   ],
   "source": [
    "# 查看分词之后的情况 随机查看\n",
    "print(content_s[random.randint(1,193)])\n",
    "\n",
    "print(len(content_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'stopwords/stop_words_zh.txt' does not exist: b'stopwords/stop_words_zh.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0af6ae9f989e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 读取停用词，停用词的使用，是为减少一个常见词语对这个语意的影响\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords/stop_words_zh.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stopword'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/crawler/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/crawler/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/crawler/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/crawler/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/crawler/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'stopwords/stop_words_zh.txt' does not exist: b'stopwords/stop_words_zh.txt'"
     ]
    }
   ],
   "source": [
    "# 读取停用词，停用词的使用，是为减少一个常见词语对这个语意的影响\n",
    "stopwords = pandas.read_csv('stopwords/stop_words_zh.txt',index_col=False, sep=\"\\t\", quoting = 3, names=['stopword'], encoding='utf-8')\n",
    "stopwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉停用词\n",
    "def drop_stopword(contents, stopwords):\n",
    "    content_clean = []\n",
    "    for line in contents:\n",
    "        line_clean = []\n",
    "        for word in line:\n",
    "            if word in stopwords:\n",
    "                continue\n",
    "            line_clean.append(word)            \n",
    "        content_clean.append(line_clean)\n",
    "    return content_clean\n",
    "\n",
    "contents = df_content.contene_s.values.tolist()\n",
    "stopwords = stopwords.stopword.values.tolist()\n",
    "content_clean =drop_stopword(contents, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[工商, 审批, 10, 多天, 没, 进展, 不是, 说好, 一到, 2, 工作日]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[甘肃, 处处, 落后, 网站, 不, 例外, 经济, 发展, 模式, 不好, 抄, 照搬,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[尊敬, 领导, 之前, 教师, 职称, 评审, 政策, 都, 班主任, 工作, 年限, 不...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[政府, 采购, 协议, 供货, 合同, 以前, 采用, 人工, 备案, 财政厅, 需要, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[甘肃, 公安, 政务, 服务平台, 浏览器, 不, 兼容, 360, 浏览器, 每次, 登...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       content_clean  label\n",
       "0        [工商, 审批, 10, 多天, 没, 进展, 不是, 说好, 一到, 2, 工作日]      1\n",
       "1  [甘肃, 处处, 落后, 网站, 不, 例外, 经济, 发展, 模式, 不好, 抄, 照搬,...      1\n",
       "2  [尊敬, 领导, 之前, 教师, 职称, 评审, 政策, 都, 班主任, 工作, 年限, 不...      1\n",
       "3  [政府, 采购, 协议, 供货, 合同, 以前, 采用, 人工, 备案, 财政厅, 需要, ...      1\n",
       "4  [甘肃, 公安, 政务, 服务平台, 浏览器, 不, 兼容, 360, 浏览器, 每次, 登...      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content_drop = pandas.DataFrame({\"content_clean\": content_clean, 'label':all_content['label']})\n",
    "df_content_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "企业法人注册一直显示实名认证失败，但是个人注册可以，不知道能否改进下，让企业法人注册方便一点，开一个公司不容易，好几天先注册不上，很浪费时间的，麻烦有关领导看见了能不能改进下。\n",
      "注册 企业法人 改进 不上 浪费时间\n"
     ]
    }
   ],
   "source": [
    "# 使用jieba分析语句中重要的词语，提取一段的关键词，减少阅读量   参数topK 是最后返回数据的类型\n",
    "import jieba.analyse\n",
    "index = 80\n",
    "print(sug_content['content'][index])\n",
    "content_s_str = \"\".join(content_s[index])\n",
    "print(' '.join(jieba.analyse.extract_tags(content_s_str, topK = 5, withWeight = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数据用于词云使用\n",
    "words_count = df_all_drop.groupby(by=['all_words'])['all_words'].agg({\"counts\": numpy.size})\n",
    "words_count = words_count.reset_index().sort_values(by=['counts'], ascending = False)\n",
    "words_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画词云\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(font_path= 'ZhuLangXinSong-BiaoZhun/ZhuLangXinSong-BiaoZhun-2.otf',background_color='white', max_font_size=80)\n",
    "word_frequence = {x[0]:x[1] for x in words_count.head(300).values}\n",
    "wordcloud = wordcloud.fit_words(word_frequence)\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用LDA：主题模型\n",
    "格式要求：list of list，分词好的整个语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(content_clean)\n",
    "corpus = [dictionary.doc2bow(sentence) for sentence in content_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类似Kmeans \n",
    "lda = gensim.models.LdaModel(corpus = corpus, id2word = dictionary, num_topics = 3)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015*\"月\" + 0.014*\"办理\" + 0.013*\"年\" + 0.009*\"日\" + 0.008*\"需要\"\n"
     ]
    }
   ],
   "source": [
    "# 1号分类结果\n",
    "print(lda.print_topic(1,topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011*\"年\" + 0.010*\"不\" + 0.008*\"月\" + 0.008*\"办理\" + 0.006*\"没有\"\n",
      "0.015*\" \" + 0.009*\"办理\" + 0.009*\"申请\" + 0.008*\"需要\" + 0.007*\"没有\"\n",
      "0.016*\"办理\" + 0.012*\"公司\" + 0.011*\"不\" + 0.011*\"名称\" + 0.010*\"申请\"\n"
     ]
    }
   ],
   "source": [
    "for topic in lda.print_topics(num_topics = 3, num_words = 5):\n",
    "    print(topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印有多少个分类\n",
    "all_content.label.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本来的标签值就是为123，所有不需要做标签值的转变\n",
    "# # 把lable的值换成是数字\n",
    "# label_mapping = {\"建议\":1, \"咨询\":2, \"投诉\":3}\n",
    "# all_content['label'] = all_content['label'].map(label_mapping)\n",
    "# all_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2655,)\n",
      "(2655, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_content_drop['content_clean'].shape)\n",
    "print(all_content.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[工商, 审批, 10, 多天, 没, 进展, 不是, 说好, 一到, 2, 工作日]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[甘肃, 处处, 落后, 网站, 不, 例外, 经济, 发展, 模式, 不好, 抄, 照搬,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[尊敬, 领导, 之前, 教师, 职称, 评审, 政策, 都, 班主任, 工作, 年限, 不...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[政府, 采购, 协议, 供货, 合同, 以前, 采用, 人工, 备案, 财政厅, 需要, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[甘肃, 公安, 政务, 服务平台, 浏览器, 不, 兼容, 360, 浏览器, 每次, 登...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       content_clean  label\n",
       "0        [工商, 审批, 10, 多天, 没, 进展, 不是, 说好, 一到, 2, 工作日]      1\n",
       "1  [甘肃, 处处, 落后, 网站, 不, 例外, 经济, 发展, 模式, 不好, 抄, 照搬,...      1\n",
       "2  [尊敬, 领导, 之前, 教师, 职称, 评审, 政策, 都, 班主任, 工作, 年限, 不...      1\n",
       "3  [政府, 采购, 协议, 供货, 合同, 以前, 采用, 人工, 备案, 财政厅, 需要, ...      1\n",
       "4  [甘肃, 公安, 政务, 服务平台, 浏览器, 不, 兼容, 360, 浏览器, 每次, 登...      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分数据  训练集和测试集默认分为3/1  test_size= 0~1\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_content_drop['content_clean'].values, df_content_drop['label'].values, random_state = 1, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['个体户', '名称', '申请', '审核', '都', '好', '几天', '没有', '一点', '进展', '现在', '不是', '简化', '程序', '还', '慢']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1991,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#打印训练集大小\n",
    "print(x_train[1])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好 2013 年 甘肃农业大学 取得 农业 推广 硕士学位 当时 报考 在职 研究生 没有 毕业证 学位证 不 知道 报考\n"
     ]
    }
   ],
   "source": [
    "# 列表转字符串\n",
    "words = []\n",
    "for line_index in range(len(x_train)):\n",
    "    try:\n",
    "        words.append(' '.join(x_train[line_index]))\n",
    "    except IndexError:\n",
    "        print(line_index, words.index)\n",
    "print(words[0])\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird', 'cat', 'dog', 'fish']\n",
      "[[0 1 1 1]\n",
      " [0 2 1 0]\n",
      " [1 0 0 1]\n",
      " [1 0 0 0]\n",
      " [1 1 0 0]]\n",
      "[3 4 2 2]\n"
     ]
    }
   ],
   "source": [
    "# 测试词语转向量\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "texts = ['dog cat fish', 'dog cat cat', 'fish, bird', 'bird','bird cat']\n",
    "cv = CountVectorizer()\n",
    "cv_fit = cv.fit_transform(texts)\n",
    "\n",
    "# 打印结果\n",
    "# 打印所有的词语\n",
    "print(cv.get_feature_names())\n",
    "# 打印词语占的向量\n",
    "print(cv_fit.toarray())\n",
    "# 打印合计\n",
    "print(cv_fit.toarray().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词语转向量 设置转换规则 计数\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(analyzer='word', max_features=5000, lowercase = False)\n",
    "vec.fit(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifer = MultinomialNB()\n",
    "classifer.fit(vec.transform(words), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好 政务网 企业 登录 后 需要 进行 企业 信息 变更 出现 确认 企业 信息 窗口 工商 密码 填写 告知 谢谢'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试集数据处理\n",
    "test_words = []\n",
    "for line_index in range(len(x_test)):\n",
    "    try:\n",
    "        test_words.append(' '.join(x_test[line_index]))\n",
    "    except:\n",
    "        print(line_index, word_index)\n",
    "test_words[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8765060240963856"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印准确率\n",
    "classifer.score(vec.transform(test_words), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 方法2 tf词频使用的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用tf词频\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', max_features = 5000, lowercase = False)\n",
    "vectorizer.fit(words)\n",
    "# 打印结果\n",
    "# 训练\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifer = MultinomialNB()\n",
    "classifer.fit(vectorizer.transform(words), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8358433734939759"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印准确率\n",
    "classifer.score(vectorizer.transform(test_words), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 验证数据\n",
    "# perdict_data = cv.fit_transform(x_train[1])\n",
    "# perdict_data\n",
    "# classifer.predict(perdict_data)\n",
    "# classifer.predict(vec.transform(x_train[1882]))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证某条数据\n",
    "new_str = '甘肃省省领导： 我公司景泰长城冶炼有限责任公司，在2016年电力用户和发电企业的直购电交易上'\n",
    "perdict_str = jieba.lcut(new_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义去掉停用词函数\n",
    "def drop_stopword_peridict(contents, stopwords):\n",
    "    content_clean = []\n",
    "    for word in contents:\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        content_clean.append(word)            \n",
    "    return content_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉停用词\n",
    "peridict_clean =drop_stopword_peridict(perdict_str, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'咨询'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifer_dict = {1: \"建议\", 2: \"咨询\",3: \"投诉\"}\n",
    "classifer_dict[classifer.predict(vec.transform(peridict_clean))[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  因为咨询的数据量过大，在这里里面成为了主要的分类。 模型的正确率不是很高， 可以有两个地方提高正确率，\n",
    "# 1.数据采集，需要均衡三类数据，\n",
    "# 2.停用词，需要对具体情况进行，因为时间的原因，我在网上找了很多的停用词来使用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "crawler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
